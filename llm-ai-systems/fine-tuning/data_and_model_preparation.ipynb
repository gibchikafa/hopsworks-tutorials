{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4392c184-cc3b-4ded-8d2e-31c12c49ecf6",
   "metadata": {},
   "source": [
    "##  Fine-tune Llama 3.1 (8B parameter) using Ray Framework on Hopsworks\n",
    "This tutorial demonstrates how to perform fine-tuning (with LoRA and deepspeed) of a Llama 3.1 (8B) using the Ray framework on Hopsworks. Ray is an industry-leading distributed computing framework. This tutorial was run on OVH cluster but you can use any cloud provider of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9d0a6-3cda-4882-82e6-d3eb6b1f5a79",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "To perform the steps in this tutorial, you need to create a Hopsworks Kubernetes cluster with Ray enabled. For the fine-tuning task demonstrated in this example, these are the minimum resources required:\n",
    "* 1 x <b>B3-64</b> (16 CPU 64 GB RAM) for the Ray head\n",
    "* 8 x <b>T2-LE-90</b> (30 CPU, 90 GB RAM, 2x 32 GRAM Tesla V100S) for the workers\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400ddf9-5b27-4786-b165-0dea0e109618",
   "metadata": {},
   "source": [
    "### Step 1: Dataset preparation\n",
    "We are going to fine-tune the model for question answering. We need to prepare the dataset that will be used for supervised fine-tuning in a certain format. There is no specific prompt format required for the pre-trained Llama 3.1 so the dataset preprocessing can follow any prompt-completion style. The instruction-tuned models (Meta-Llama-3.1-{8,70,405}B-Instruct) use a multi-turn conversation prompt format that structures the conversation between the users and the models.\n",
    "\n",
    "The dataset for QA typically includes the following fields:\n",
    "\n",
    "* Question: The input question to the model.\n",
    "* Context (optional): A passage or text providing information the model should use to answer.\n",
    "* Answer: The correct response.\n",
    "\n",
    "This example is configured to fine-tune the Llama 3.1 8B pre-trained model on the GSM8K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adf6a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4de50ea7-9c67-4ebe-8fea-0956d50312bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_dir = \"Resources/llama_finetuning\"\n",
    "HOPSFS_STORAGE_PATH = os.path.join(os.environ.get(\"PROJECT_PATH\"), llama_dir)\n",
    "if not os.path.exists(HOPSFS_STORAGE_PATH):\n",
    "    os.mkdir(HOPSFS_STORAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3baa764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/hopsfs/Resources/llama_finetuning/datasets/tokens.json' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "dataset_splits = {\"train\": dataset[\"train\"], \"test\": dataset[\"test\"]}\n",
    "dataset_dir = os.path.join(HOPSFS_STORAGE_PATH, \"datasets\")\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.mkdir(dataset_dir)\n",
    "    \n",
    "with open(os.path.join(dataset_dir, \"tokens.json\"), \"w\") as f:\n",
    "    tokens = {}\n",
    "    print(f)\n",
    "    tokens[\"tokens\"] = [\"<START_Q>\", \"<END_Q>\", \"<START_A>\", \"<END_A>\"]\n",
    "    f.write(json.dumps(tokens))\n",
    "    for key, ds in dataset_splits.items():\n",
    "        with open(os.path.join(dataset_dir, f\"{key}.jsonl\"), \"w\") as f:\n",
    "            for item in ds:\n",
    "                newitem = {}\n",
    "                newitem[\"input\"] = (\n",
    "                    f\"<START_Q>{item['question']}<END_Q>\"\n",
    "                    f\"<START_A>{item['answer']}<END_A>\"\n",
    "                )\n",
    "                f.write(json.dumps(newitem) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686f075-a33e-4b1e-b20e-1b05dbede50a",
   "metadata": {},
   "source": [
    "### Step 2: Download the pre-trained model\n",
    "The next step is to download the pre-trained Llama model from hugging face. For this you will need the hugging face token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb3b68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils.hub import TRANSFORMERS_CACHE\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5effab1-04b8-49fc-88e1-a02df4e89456",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"<YOUR HUGGING FACE TOKEN>\"\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b278bb45-c87d-440e-8649-dcf68621997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c9b79aa6d44e00ae339658b7193ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb85d1b4eace4654b81fb61cc327bec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133f3ba47fad49dab555132d2c44e54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b6538b78f34431a7df398f66344199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60803ab38f0406eb863c3d2019d1bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c97c887d00e4668b4436691637dcfef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823151aa537041e1a62a00abe61290f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a342280ddd724ddca4083b5649122ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a312753604f14dc6ac06fd34df389474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac77dfd4b4b4b78867d8db30c579155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05249250193b47ebad345baf71529e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4dd545de0f412a95e6205efef0e7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the pre-trained model from Hugging face\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec0badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['special_tokens_map.json',\n",
       " 'model-00002-of-00004.safetensors',\n",
       " 'model-00001-of-00004.safetensors',\n",
       " 'model-00003-of-00004.safetensors',\n",
       " 'config.json',\n",
       " 'tokenizer.json',\n",
       " 'model-00004-of-00004.safetensors',\n",
       " 'tokenizer_config.json',\n",
       " 'generation_config.json',\n",
       " 'model.safetensors.index.json']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_dir = os.path.join(TRANSFORMERS_CACHE, f\"models--{model_id.replace('/', '--')}\")\n",
    "snapshots_dir = os.path.join(local_model_dir, \"snapshots\")\n",
    "blobs_dir = os.path.join(snapshots_dir, next(d for d in os.listdir(snapshots_dir) if os.path.isdir(os.path.join(snapshots_dir, d))))\n",
    "os.listdir(blobs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c036501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hopsfs_model_dir = os.path.join(HOPSFS_STORAGE_PATH, f\"models--{model_id.replace('/', '--')}\")\n",
    "if not os.path.exists(hopsfs_model_dir):\n",
    "    os.mkdir(hopsfs_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4bf6ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Failed to copy pre-trained model files to hopsfs",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m cp_cmd \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcp -L -r \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mblobs_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/* \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhopsfs_model_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m result \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39msystem(cp_cmd)\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m result \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to copy pre-trained model files to hopsfs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mAssertionError\u001B[0m: Failed to copy pre-trained model files to hopsfs"
     ]
    }
   ],
   "source": [
    "# copy the downloaded model to hopsfs\n",
    "cp_cmd = f\"cp -L -r {blobs_dir}/* {hopsfs_model_dir}\"\n",
    "result = os.system(cp_cmd)\n",
    "assert result != 0, \"Failed to copy pre-trained model files to hopsfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492db64-88a7-431b-9bee-217aacb5916b",
   "metadata": {},
   "source": [
    "### Step 3: Create the ray job for the fine-tuning task\n",
    "We are going to use the hopsworks jobs api to create and run the job for the fine-tuning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e48c95-f236-4ebe-be27-f6f585813843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "2025-01-09 07:01:22,956 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://hopsworks.ai.local/p/119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff06133e9884523a6cbdfbf1b46070e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /hopsfs/Jupyter/ray_llm_finetuning.py: 0.000%|          | 0/28956 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10493ca0e0b44d38bfa2dcfabf056880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /hopsfs/Jupyter/llama_fine_tune_runtime_env.yaml: 0.000%|          | 0/341 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "app_file_path = dataset_api.upload(\"ray_llm_finetuning.py\", llama_dir, overwrite=True)\n",
    "environment_config_yaml_path = dataset_api.upload(\"llama_fine_tune_runtime_env.yaml\", llama_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ad7ec-0822-4893-ab85-e78aab0ee372",
   "metadata": {},
   "source": [
    "### About the runtime environment file\n",
    "The runtime environment file contains the dependencies required for the Ray job including files, packages, environment variables, and more. This is useful when you need to install specific packages and set environment variables for this particular Ray job. It should be provided as a YAML file. In this example, the runtime environment file has the following configuration.\n",
    "```\n",
    "pip:\n",
    "  - transformers==4.44.0\n",
    "  - accelerate==0.31.0\n",
    "  - peft==0.11.1\n",
    "  - deepspeed==0.16.2\n",
    "env_vars:\n",
    "  LIBRARY_PATH: \"$CUDA_HOME/lib64:$LIBRARY_PATH\"\n",
    "  PROJECT_DIR: \"/home/yarnapp/hopsfs\"\n",
    "  TRAINED_MODEL_STORAGE_PATH: \"${PROJECT_DIR}/Resources/llama_finetuning/fine-tuned-model\" # Where the fine-tuned model will be saved\n",
    "  TRAINING_DATA_DIR: \"${PROJECT_DIR}/Resources/llama_finetuning/datasets\" # dataset location\n",
    "  TRAINING_CONFIGURATION_DIR: \"${PROJECT_DIR}/Resources/llama_finetuning/configs\" # location for deepspeed and lora configuration files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30caad87-ba34-430b-8400-3cfdb6c21c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created successfully, explore it at https://hopsworks.ai.local/p/119/jobs/named/ray_llama_finetuning\n"
     ]
    }
   ],
   "source": [
    "jobs_api = project.get_jobs_api()\n",
    "\n",
    "ray_config = jobs_api.get_configuration(\"RAY\")\n",
    "pretrained_path = \"/home/yarnapp\" + hopsfs_model_dir\n",
    "ray_config['appPath'] = os.path.join('/Projects/'+project.name, app_file_path)\n",
    "ray_config['environmentName'] = \"ray-torch-training-pipeline\"\n",
    "ray_config['driverCores'] = 8\n",
    "ray_config['driverMemory'] = 34816\n",
    "ray_config['workerCores'] = 28\n",
    "ray_config['workerMemory'] = 34816\n",
    "ray_config['minWorkers'] = 8\n",
    "ray_config['maxWorkers'] = 8\n",
    "ray_config['workerGpus'] = 2\n",
    "ray_config['runtimeEnvironment'] = os.path.join('/Projects/'+project.name, environment_config_yaml_path)\n",
    "ray_config['defaultArgs'] = f\"--model-name models-meta-llama-Meta-Llama-3.1-8B-Instruct --mx fp16 --lora --num-devices=16 --num-epochs=1 --lr=5e-4 --batch-size-per-device=16 --eval-batch-size-per-device=16 --pre-trained-path {pretrained_path}\"\n",
    "\n",
    "job = jobs_api.create_job(job_name, ray_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f58da-c240-45d4-ab23-2ecb89152fcc",
   "metadata": {},
   "source": [
    "## Step 4: Run the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4d0cfa5-afe5-4682-a2b5-dad97a7ef280",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_job = jobs_api.get_job(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840d9f2-32ae-41b0-a829-ecd72247ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8c427-2f2c-4e8e-b36e-83c213a77669",
   "metadata": {},
   "source": [
    "After the job is run you can go to the hopsworks UI to monitor the job execution. From executions page, you can open the Ray dashboard. In the Ray Dashboard, you can monitor the resources used by the job, the number of workers, logs, and the tasks that are running. \n",
    "\n",
    "After the job finishes running successfully, the fine-tuned model will be saved in the directory specified in the TRAINED_MODEL_STORAGE_PATH variable defined in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c7a6d-8fdd-4a3f-bc45-d4175d54a895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
